# -*- coding: utf-8 -*-
"""crawling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BG0k3VZBRy60NOxFwaQptSZMRaJSAoEJ

###초기설정
"""

!pip install youtube_transcript_api fpdf google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client

pip install fpdf

"""###종별 강아지 특징 검색 시 등장하는 TOP10 정보 crawling"""

from googleapiclient.discovery import build
from youtube_transcript_api import YouTubeTranscriptApi
import os

# YouTube API 키 설정 (환경 변수로부터 로드하는 것이 더 안전함)
api_key = os.getenv('YOUTUBE_API_KEY', '') #여기에 key 작성하기
youtube = build('youtube', 'v3', developerKey=api_key)

# 특정 검색어로 상위 5개의 동영상 ID 가져오기
def get_video_ids_from_search(query, max_results=10):
    video_ids = []
    request = youtube.search().list(
        part="id",
        q=query,
        maxResults=max_results,
        type="video",
        order="relevance"  # 가장 관련성이 높은 순서대로 정렬
    )
    response = request.execute()

    for item in response['items']:
        video_ids.append(item['id']['videoId'])

    return video_ids

# 유튜브 동영상에서 자막 추출하기
def get_youtube_transcript(video_id):
    try:
        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ko', 'en'])  # 한국어와 영어 자막을 모두 가져오기
        transcript = ""
        for entry in transcript_list:
            transcript += entry['text'] + " "
        return transcript
    except Exception as e:
        # 자막을 가져오지 못한 경우 None 반환
        print(f"Error retrieving transcript for video {video_id}: {e}")
        return None

# 모든 자막을 한 파일로 저장하는 함수
def save_texts_to_file(all_texts, filename="transcripts.txt"):
    with open(filename, "w", encoding="utf-8") as file:
        for idx, transcript in enumerate(all_texts, start=1):
            # 파일에 각 비디오의 자막 추가, 비디오 번호를 구분자로 사용
            file.write(f"\n[Video {idx} Transcript]\n")
            file.write(transcript + "\n")

# 메인 함수: 검색어로 상위 10개 동영상의 자막을 추출하여 파일로 저장
def main(query, output_filename):
    # 1. 검색어로 상위 10개의 동영상 ID 가져오기
    video_ids = get_video_ids_from_search(query)

    all_texts = []

    # 2. 각 동영상의 자막을 추출하여 텍스트로 저장
    for video_id in video_ids:
        transcript = get_youtube_transcript(video_id)
        if transcript:
            all_texts.append(transcript)

    # 3. 모든 자막을 한 파일에 저장
    if all_texts:
        save_texts_to_file(all_texts, output_filename)
        print(f"모든 자막이 파일에 저장되었습니다: {output_filename}")
    else:
        print("자막이 포함된 동영상을 찾지 못했습니다.")

# 검색어와 파일 이름 설정
query = '종별 강아지 특징'  # 유튜브에서 검색할 키워드
output_filename = 'Top10_transcript.txt'

# 실행
if __name__ == "__main__":
    main(query, output_filename)

"""###특정 유튜버의 동영상에 대한 정보 크롤링"""

from googleapiclient.discovery import build
from youtube_transcript_api import YouTubeTranscriptApi
import os

# YouTube API 키 설정 (환경 변수로부터 로드하는 것이 더 안전함)
api_key = os.getenv('YOUTUBE_API_KEY', '') #key 작성하기
youtube = build('youtube', 'v3', developerKey=api_key)

# 특정 재생목록에서 모든 동영상 ID 가져오기 (페이지네이션을 통해 모든 동영상 체크)
def get_video_ids_from_playlist(playlist_id):
    video_ids = []
    next_page_token = None

    while True:
        request = youtube.playlistItems().list(
            part="contentDetails",
            playlistId=playlist_id,
            maxResults=50,  # 최대 50개의 결과를 한 번에 가져옴 (API 제한)
            pageToken=next_page_token  # 다음 페이지로 넘어가기 위한 토큰
        )
        response = request.execute()

        for item in response['items']:
            video_ids.append(item['contentDetails']['videoId'])

        # 다음 페이지 토큰이 있는지 확인 (없으면 마지막 페이지)
        next_page_token = response.get('nextPageToken')

        if not next_page_token:  # 더 이상 페이지가 없으면 종료
            break

    return video_ids

# 유튜브 동영상에서 자막 추출하기
def get_youtube_transcript(video_id):
    try:
        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ko', 'en'])  # 한국어와 영어 자막을 모두 가져오기
        transcript = ""
        for entry in transcript_list:
            transcript += entry['text'] + " "
        return transcript
    except Exception as e:
        # 자막을 가져오지 못한 경우 None 반환
        print(f"Error retrieving transcript for video {video_id}: {e}")
        return None

# 모든 자막을 한 파일로 저장하는 함수
def save_texts_to_file(all_texts, filename="transcripts.txt"):
    with open(filename, "w", encoding="utf-8") as file:
        for idx, transcript in enumerate(all_texts, start=1):
            # 파일에 각 비디오의 자막 추가, 비디오 번호를 구분자로 사용
            file.write(f"\n[Video {idx} Transcript]\n")
            file.write(transcript + "\n")

# 메인 함수: 재생목록에 있는 모든 동영상의 자막을 추출하여 파일로 저장
def main(playlist_id, output_filename):
    # 1. 재생목록에서 모든 동영상 ID 가져오기
    print(f"Fetching all video IDs from playlist: {playlist_id}")
    video_ids = get_video_ids_from_playlist(playlist_id)

    all_texts = []

    # 2. 각 동영상의 자막을 추출하여 텍스트로 저장
    for video_id in video_ids:
        transcript = get_youtube_transcript(video_id)
        if transcript:
            all_texts.append(transcript)

    # 3. 모든 자막을 한 파일에 저장
    if all_texts:
        save_texts_to_file(all_texts, output_filename)
        print(f"모든 자막이 파일에 저장되었습니다: {output_filename}")
    else:
        print("자막이 포함된 동영상을 찾지 못했습니다.")

# '견종백과' 재생목록 ID
playlist_id = 'PLVh3TM0B0WtksY4ZQVNdD0aTG1Qm1mQNM'
output_filename = 'KangDog-transcripts.txt'

# 실행
if __name__ == "__main__":
    main(playlist_id, output_filename)

"""###transcript 요약해서 최종 txt 파일 도출"""

# openai 를 사용해서 요약하는 걸로
!pip install openai

import openai
import os

# Set your OpenAI API key
# openai.api_key = os.getenv("") #openai key 작성하기

#요약
def summarize_text_with_openai(text):
    response = openai.Completion.create(
        engine="gpt-3.5-turbo",  #사용하는 gpt 버전에 따라,..
        prompt=f"Summarize the following transcript:\n\n{text}",
        max_tokens=150,  # 요약본 길이 조절
        temperature=0.5,
    )
    return response.choices[0].text.strip()


def summarize_transcripts(input_file, output_file):
    with open(input_file, "r", encoding="utf-8") as infile:
        transcripts = infile.read()

    # Split by video sections
    video_sections = transcripts.split("\n[Video")

    all_summaries = []

    for idx, section in enumerate(video_sections):
        if section.strip():  # Skip
            if idx > 0:
                section = "[Video" + section


            summary = summarize_text_with_openai(section)
            all_summaries.append(f"[Video {idx + 1} Summary]\n{summary}\n")

    # to the output file
    with open(output_file, "w", encoding="utf-8") as outfile:
        outfile.writelines(all_summaries)

    print(f"Summaries have been saved to {output_file}")

#result
input_file = "KangDog-transcripts.txt"
output_file = "summary_transcripts_openai.txt"

# Summarize transcripts and save to the output file
summarize_transcripts(input_file, output_file)